对周志华的机器学习（西瓜书）的一些备忘

1. 绪论
 
    - 归纳偏好

        > 任何机器学习都有对某种类型假设的偏好

        > 一般性原则：奥卡姆剃刀，如果有多个假设与观察一致，选择最简单的。

        > 总误差与学习算法无关，称为“没有免费的午餐”定理
        
        > 学习算法的相对优劣需要针对具体的问题，需要归纳偏好与问题相匹配。

    -  多释原则，保留与经验观察一致的所有假设；这个和集成学习的研究相吻合。

2. 模型评估与选择

    - 经验误差与过拟合
    
        > m个样本中有a个分类错误：错误率=a/m、精度=1-a/m
        
        > 误差，训练误差/经验误差，新样本上：泛化误差。
        
        > 过拟合、欠拟合

    - 评估方法
       
       > 留出法 数据集D 分为 训练集S 和 测试集T  S,T 互斥 

       > 交叉验证法 将数据集分为k个大小相同的子集，然后k-1为训练集，1为测试集

       > 自助法 将数据集D随机重复采样m次得到D'，这样会有38%的样本没有被采样，将 D' 作为训练集， D\D' 作为测试集。

    - 性能度量
       
       > 回归，性能度量为均方误差

       > 查准率、查全率、F1

       > TP 真正例 FP 假正例    FN 假反例 TN 真反例

       > 查准率 P = TP / (TP+FP) 查全率 R = TP / (TP+FN)

       > P-R 曲线 差准率为纵轴，查全率为横轴；

       > 如果一个学习器的P-R曲线被另一个包住，则后者优于前者 

       > 平衡点：查准率=查全率

       > F1 度量： F1 = 2 x P x R /(P+R) = 2xTP/(样本总数+TP-TN)

       > Fb = (1+b^2)*P*R/(b^2*P+R) b>0 查全率更重要， b<0 查准率更重要， b=1 ,Fb=F1

       > ROC , 纵轴 TPR = TP/(TP+FN) ，横轴 FPR=FP/(TN+FP)

       > ROC 和 P-R 曲线一样，如果一个学习器的P-R曲线被另一个包住，则后者优于前者

       > AUC ROC曲线下的面积

       > 非均等代价，代价曲线

    - 比较检验

    


